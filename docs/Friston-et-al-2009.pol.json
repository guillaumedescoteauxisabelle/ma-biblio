{
  "version": 1,
  "items": [
    {
      "id": "12hPatgexy",
      "guid": "1e3avJV6ns",
      "created": "2021-01-03T13:12:00.967Z",
      "lastUpdated": "2021-01-03T13:29:04.805Z",
      "rects": {
        "0": {
          "left": 89,
          "top": 895,
          "right": 411,
          "bottom": 908,
          "width": 322,
          "height": 13
        },
        "1": {
          "left": 77,
          "top": 909,
          "right": 253,
          "bottom": 922,
          "width": 175,
          "height": 13
        },
        "2": {
          "left": 251,
          "top": 909,
          "right": 365,
          "bottom": 922,
          "width": 114,
          "height": 13
        }
      },
      "textSelections": {
        "0": {
          "text": "We start with the premise that adaptive agents or phenotypes"
        },
        "1": {
          "text": "must occupy a limited repertoire of"
        },
        "2": {
          "text": "states. See Friston et al"
        }
      },
      "text": {
        "TEXT": "We start with the premise that adaptive agents or phenotypes must occupy a limited repertoire of states. See Friston et al"
      },
      "images": {},
      "notes": {},
      "questions": {},
      "flashcards": {},
      "color": "yellow",
      "revisedText": {
        "HTML": "<p>Important to limit the goals an agent has.&nbsp; </p><p><span style=\"letter-spacing: 0.01071em;\">&gt;We start with the premise that adaptive agents or phenotypes must occupy a limited repertoire of states.</span></p><p><span style=\"letter-spacing: 0.01071em;\"><br></span></p>"
      },
      "tags": {
        "AIDesign": {
          "id": "AIDesign",
          "label": "AIDesign"
        },
        "ArticleAgent": {
          "id": "ArticleAgent",
          "label": "ArticleAgent"
        },
        "AgentDesign": {
          "id": "AgentDesign",
          "label": "AgentDesign"
        }
      }
    },
    {
      "id": "1LHMqkejmz",
      "guid": "1Rfg392fFc",
      "created": "2021-01-03T13:12:12.385Z",
      "lastUpdated": "2021-01-03T13:12:17.407Z",
      "rects": {
        "0": {
          "left": 77,
          "top": 879,
          "right": 216,
          "bottom": 894,
          "width": 139,
          "height": 14
        }
      },
      "textSelections": {
        "0": {
          "text": "The free-energy principle"
        }
      },
      "text": {
        "TEXT": "The free-energy principle"
      },
      "images": {},
      "notes": {},
      "questions": {},
      "flashcards": {},
      "color": "yellow",
      "revisedText": {
        "HTML": "<h1>The free-energy principle</h1>"
      }
    },
    {
      "id": "12dQLajPLp",
      "guid": "1yvSeBUuTv",
      "created": "2021-01-03T13:12:22.001Z",
      "lastUpdated": "2021-01-03T13:12:27.924Z",
      "rects": {
        "0": {
          "left": 77,
          "top": 75,
          "right": 605,
          "bottom": 104,
          "width": 527,
          "height": 29
        }
      },
      "textSelections": {
        "0": {
          "text": "Reinforcement Learning or Active Inference?"
        }
      },
      "text": {
        "TEXT": "Reinforcement Learning or Active Inference?"
      },
      "images": {},
      "notes": {},
      "questions": {},
      "flashcards": {},
      "color": "yellow",
      "revisedText": {
        "HTML": "<h1>Reinforcement Learning or Active Inference?</h1>"
      }
    },
    {
      "id": "1wmLywEMrq",
      "guid": "12injAP4va",
      "created": "2021-01-03T13:16:27.789Z",
      "lastUpdated": "2021-01-03T13:23:39.405Z",
      "rects": {
        "0": {
          "left": 77,
          "top": 117,
          "right": 164,
          "bottom": 132,
          "width": 87,
          "height": 14
        },
        "1": {
          "left": 166,
          "top": 117,
          "right": 171,
          "bottom": 132,
          "width": 5,
          "height": 14
        },
        "2": {
          "left": 171,
          "top": 117,
          "right": 384,
          "bottom": 132,
          "width": 212,
          "height": 14
        }
      },
      "textSelections": {
        "0": {
          "text": "Karl J. Friston"
        },
        "1": {
          "text": "*"
        },
        "2": {
          "text": ", Jean Daunizeau, Stefan J. Kiebel"
        }
      },
      "text": {
        "TEXT": "Karl J. Friston * , Jean Daunizeau, Stefan J. Kiebel"
      },
      "images": {},
      "notes": {},
      "questions": {},
      "flashcards": {},
      "color": "red",
      "revisedText": {
        "HTML": "<p><span>\n</span></p><p>Citer: (Friston et al., 2009)</p>\n<p>FTag: Friston-et-al-2009</p>\n<p>APA7: Friston, K. J., Daunizeau, J., &amp; Kiebel, S. J. (2009). Reinforcement Learning or Active Inference? <em>PLOS ONE</em>, <em>4</em>(7), e6421. <a href=\"https://doi.org/10.1371/journal.pone.0006421\">https://doi.org/10.1371/journal.pone.0006421</a></p>\n<p><a href=\"https://app.simplenote.com/p/45MQ5Q\">https://app.simplenote.com/p/45MQ5Q</a></p>\n\n<p></p><p><span><br></span></p>"
      }
    }
  ]

}





