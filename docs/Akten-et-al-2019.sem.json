{"csl":{"id":"http://zotero.org/users/180474/items/IN9DFCGU","type":"paper-conference","abstract":"The authors present a visual instrument developed as part of the creation of the artwork Learning to See. The artwork explores bias in artificial neural networks and provides mechanisms for the manipulation of specifically trained-for real-world representations. The exploration of these representations acts as a metaphor for the process of developing a visual understanding and/or visual vocabulary of the world. These representations can be explored and manipulated in real time, and have been produced in such a way so as to reflect specific creative perspectives that call into question the relationship between how both artificial neural networks and humans may construct meaning.","collection-title":"SIGGRAPH '19","container-title":"ACM SIGGRAPH 2019 Art Gallery","DOI":"10.1145/3306211.3320143","event-place":"Los Angeles, California","ISBN":"978-1-4503-6311-2","note":"ZSCC: 0000000","page":"1â€“6","publisher":"Association for Computing Machinery","publisher-place":"Los Angeles, California","source":"ACM Digital Library","title":"Learning to see: you are what you see","title-short":"Learning to see","URL":"http://doi.org/10.1145/3306211.3320143","author":[{"family":"Akten","given":"Memo"},{"family":"Fiebrink","given":"Rebecca"},{"family":"Grierson","given":"Mick"}],"accessed":{"date-parts":[["2020",7,3]]},"issued":{"date-parts":[["2019",7,28]]}},"annotations":{"0":{"type":"text","rendermd":"Learning to See\n===============","id":"12uxUTZFY8","created":"2020-08-05T15:59:18.379Z","color":"yellow","guid":"1v8WLi9G6b"},"1":{"type":"text","rendermd":"real-world representations","id":"12nGjsSf72","created":"2020-08-05T16:00:03.514Z","color":"#9900EF","guid":"12nGjsSf72"},"2":{"type":"text","rendermd":"We use a novel training system and custom software","id":"12faVaKm4y","created":"2020-08-05T16:04:19.635Z","color":"#FF6900","guid":"12faVaKm4y"},"3":{"type":"text","rendermd":"reconstructs a new image that resembles the input in composition and overall shape and structure","id":"1DMSmcSyuB","created":"2020-08-05T16:05:53.581Z","color":"#9900EF","guid":"1DMSmcSyuB"},"4":{"type":"ref","id":"127Tppz5kJ","created":"2020-08-05T16:11:27.015Z","guid":"127Tppz5kJ"},"5":{"type":"text","rendermd":"demonstrating how critical the training data is to the predictions that the model will make","id":"12tcHtjkrP","created":"2020-08-05T16:18:49.291Z","color":"#FF6900","guid":"12tcHtjkrP"},"6":{"type":"text","rendermd":"Metaphorically speaking, the training data determines the full life experience of the network and ultimately shapes its worldview","id":"12RTAnmcB9","created":"2020-08-05T18:59:44.294Z","color":"#9900EF","guid":"12RTAnmcB9"},"7":{"type":"ref","id":"12L1S5VBMV","created":"2020-08-05T19:01:58.702Z","guid":"12L1S5VBMV"},"8":{"type":"image","data":{"width":911,"height":526,"id":"12X2gaUoB1TLxb5tWPqq","fname":"12X2gaUoB1TLxb5tWPqq.png"},"rendermd":"![](12X2gaUoB1TLxb5tWPqq.png)","id":"12XVH5VsVF","created":"2020-08-05T19:02:55.748Z","guid":"12XVH5VsVF"},"9":{"type":"text","rendermd":"build hierarchies of representations and extract meaningful information from vast amounts of high-dimensional raw dat","id":"12cWx54F4u","created":"2020-08-07T21:54:09.314Z","color":"yellow","guid":"12cWx54F4u"},"10":{"type":"text","rendermd":"are not focusing on the potential of DL systems as a real-time human-machine collaborative tool or instrumen","id":"1hoHpp79aL","created":"2020-08-07T21:54:54.299Z","color":"#FF6900","guid":"1hoHpp79aL"},"11":{"type":"text","rendermd":"We design our system to enable users to create what can be thought of as animated content, in a real-time, interactive manner","id":"1k4T9Y1Kyo","created":"2020-08-07T21:55:06.030Z","color":"green","guid":"1k4T9Y1Kyo"},"12":{"type":"text","rendermd":"digital puppetry","id":"19KypM8PYL","created":"2020-08-07T21:55:28.344Z","color":"#9900EF","guid":"19KypM8PYL"},"13":{"type":"text","rendermd":"The second form of real-time interactivity comes through a number of parameters (which can be controlled via a MIDI controller, or a graphical user interface [GUI] ) that influence how the output image is reconstructed","id":"124pFSdThY","created":"2020-08-07T22:01:52.148Z","color":"yellow","guid":"124pFSdThY"},"14":{"type":"text","rendermd":"Network Architecture and Training","id":"1X71Jk8o2u","created":"2020-08-07T22:03:13.543Z","color":"yellow","guid":"1X71Jk8o2u"},"15":{"type":"text","rendermd":"We might even go as far as to claim that the model contains knowledge of the structure of elements related to the contents of the dataset.","id":"12YoU9icdQ","created":"2020-08-09T14:47:10.241Z","color":"yellow","guid":"12YoU9icdQ"},"16":{"type":"ref","id":"1WtnUicYRx","created":"2020-10-18T20:27:25.051Z","guid":"1WtnUicYRx"},"17":{"type":"text","rendermd":" [...] offer a range of potential creative affordances\n\n#goal","hData":{"t":" [...] offer a range of potential creative affordances\n\n","y":"goal"},"id":"12mZVSbSSM","created":"2020-10-18T20:28:38.301Z","color":"green","guid":"1SzgQhqKg9"},"18":{"type":"text","rendermd":"m.akten@gold.ac.uk","id":"1G7qrRLBtE","created":"2020-10-18T20:29:49.945Z","color":"yellow","guid":"1G7qrRLBtE"},"19":{"type":"text","rendermd":"The exploration of these representations acts as a metaphor for the process of developing a visual understanding and/or visual vocabulary of the world.","id":"1JwvNcSGnu","created":"2020-10-18T20:31:22.345Z","color":"yellow","guid":"1JwvNcSGnu"},"20":{"type":"ref","id":"12jjXfy2FRWMtQiNzEek","created":"2020-10-18T20:40:32.409Z","guid":"12jjXfy2FRWMtQiNzEek"},"21":{"type":"text","rendermd":"Akten","id":"12wR3GPK6q","created":"2020-10-19T18:30:56.648Z","color":"yellow","guid":"12wR3GPK6q"},"22":{"type":"text","rendermd":"Learning to See: You Are What You See\n=====================================","id":"1wJ7vRBWrM","created":"2020-10-19T18:31:08.453Z","color":"yellow","guid":"1gXUps9Tcd"}}}