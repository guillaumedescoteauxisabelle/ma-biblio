<h1 id="-akten-2016-">( [[Akten-2016]])</h1>
<p>autonomous collaborative creative agent</p>
<p>Monte Carlo Tree Search (MCTS)</p>
<h1 id="-edmonds-2000-">( [[Edmonds-2000]])</h1>
<p>intelligent user interface</p>
<p>promotes enhanced creative thinking</p>
<h1 id="-isola-et-al-2017-">( [[Isola-et-al-2017]])</h1>
<blockquote>
<p>It would be highly desirable if we could instead specify only a high-level goal, like “make the output indistinguishable from reality”, and then automatically learn a loss function appropriate for satisfying this goal. Fortunately, this is exactly what is done by the recently proposed Generative Adversarial Networks (GANs) [ 22 , 12 , 41 , 49 , 59 ]   (Isola et al., 2017, p.1126)</p>
</blockquote>
<h1 id="-karras-et-al-2020-">( [[Karras-et-al-2020]])</h1>
<p>unconditional image modeling,</p>
<h1 id="-poltronieri-et-hanska-2019-">( [[Poltronieri-et-Hanska-2019]])</h1>
<h2 id="gofai-good-old-fashioned-artificial-intelligence-">GOFAI (Good Old Fashioned Artificial Intelligence)</h2>
<h2 id="gans-generative-adversarial-networks-">GANs (Generative Adversarial Networks)</h2>
<h1 id="-pouyanfar-et-al-2018-">( [[Pouyanfar-et-al-2018]])</h1>
<p>Deep learning, which has its roots from conventional neural networks, significantly outperforms its predecessors. It utilizes graph technologies with transformations among neurons to develop many-layered learning models.</p>
