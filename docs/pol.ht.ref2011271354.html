<h1 id="-isola-et-al-2017-">( [[Isola-et-al-2017]])</h1>
<p>Le réseau génératif adverse (RGA) sont des modèles génératifs qui apprennent une cartographie à partir d&#39;un vecteur de bruit aléatoire vers une image tandit que le réseau génératif adverse conditionel (RGAC) apprend sa cartographie à partir d&#39;observation d&#39;image et de bruit aléatoire.</p>
<p>Je ne comprend pas encore pleinement la chose.</p>
<blockquote>
<p>GANs are generative models that learn a mapping from random noise vector z to output image y , G : z → y [ 22 ]. In contrast, conditional GANs learn a mapping from observed image x and random noise vector z , to y , G : { x, z } → y . The generator G is trained to produce outputs that cannot be distinguished from “real” images by an adversarially trained discriminator, D , which is trained to do as well as possible at detecting the generator’s “fakes”. This training procedure is diagrammed in Figure 2</p>
</blockquote>
<p>L&#39;article enquête sur les réseaux de neurones adverses conditionnels (RNAC) pour faire la translation d&#39;une image en une autre.</p>
<blockquote>
<p>We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems.  (Isola et al., 2017)</p>
</blockquote>
