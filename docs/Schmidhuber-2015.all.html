<hr>
<h2 id="fiche-cr-e-par-guillaume-d-isabelle-2020-">Fiche créée par Guillaume D.Isabelle, 2020 </h2>
<h3 id="hashtagged">HashTagged</h3>
<h1 id="deep-learning-in-neural-networks-an-overview">Deep learning in neural networks: An overview</h1>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://zotero.org/users/180474/items/IPA4SDX6">ZotWeb</a></td>
<td>article-journal</td>
<td></td>
</tr>
<tr>
<td><a href="http://www.sciencedirect.com/science/article/pii/S0893608014002135">Src Url</a></td>
<td>[[Schmidhuber]] (2015)</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="abstract">Abstract</h2>
<p>In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning &amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.</p>
<hr>
<h2 id="annotations">Annotations</h2>
<h1 id="deep-learning-in-neural-networks-an-overview">Deep learning in neural networks:An overview</h1>
<p>[[ArticleAkten]] </p>
<p>&lt;font size=-3&gt;Citer: (Schmidhuber, 2015)<br><br>FTag: Schmidhuber-2015<br><br>APA7: Schmidhuber, J. (2015). Deep learning in neural networks: An overview. <em>Neural Networks</em>, _61_, 85–117. <a href="https://doi.org/10.1016/j.neunet.2014.09.003">https://doi.org/10.1016/j.neunet.2014.09.003</a><br><br>( <a href="https://jgwill.github.io/www.fichiers/Schmidhuber-2015.cache.html">Cache</a>)&lt;/font&gt;



</p>
<h2 id="abbreviations-in-alphabetical-order">Abbreviations in alphabetical order</h2>
<p>AE:</p>
<p>Autoencoder</p>
<p>AI:</p>
<p>Artificial Intelligence</p>
<p>ANN:</p>
<p>Artificial Neural Network</p>
<p>BFGS:</p>
<p>Broyden–Fletcher–Goldfarb–Shanno</p>
<p>BNN:</p>
<p>Biological Neural Network</p>
<p>BM:</p>
<p>Boltzmann Machine</p>
<p>BP:</p>
<p>Backpropagation</p>
<p>BRNN:</p>
<p>Bi-directional Recurrent Neural Network</p>
<p>CAP:</p>
<p>Credit Assignment Path</p>
<p>CEC:</p>
<p>Constant Error Carousel</p>
<p>CFL:</p>
<p>Context Free Language</p>
<p>CMA-ES:</p>
<p>Covariance Matrix Estimation ES</p>
<p>CNN:</p>
<p>Convolutional Neural Network</p>
<p>CoSyNE:</p>
<p>Co-Synaptic Neuro-Evolution</p>
<p>CSL:</p>
<p>Context Sensitive Language</p>
<p>CTC:</p>
<p>Connectionist Temporal Classification</p>
<p>DBN:</p>
<p>Deep Belief Network</p>
<p>DCT:</p>
<p>Discrete Cosine Transform</p>
<p>DL:</p>
<p>Deep Learning</p>
<p>DP:</p>
<p>Dynamic Programming</p>
<p>DS:</p>
<p>Direct Policy Search</p>
<p>EA:</p>
<p>Evolutionary Algorithm</p>
<p>EM:</p>
<p>Expectation Maximization</p>
<p>ES:</p>
<p>Evolution Strategy</p>
<p>FMS:</p>
<p>Flat Minimum Search</p>
<p>FNN:</p>
<p>Feedforward Neural Network</p>
<p>FSA:</p>
<p>Finite State Automaton</p>
<p>GMDH:</p>
<p>Group Method of Data Handling</p>
<p>GOFAI:</p>
<p>Good Old-Fashioned AI</p>
<p>GP:</p>
<p>Genetic Programming</p>
<p>GPU:</p>
<p>Graphics Processing Unit</p>
<p>GPU-MPCNN:</p>
<p>GPU-Based MPCNN</p>
<p>HMM:</p>
<p>Hidden Markov Model</p>
<p>HRL:</p>
<p>Hierarchical Reinforcement Learning</p>
<p>HTM:</p>
<p>Hierarchical Temporal Memory</p>
<p>HMAX:</p>
<p>Hierarchical Model “and X”</p>
<p>LSTM:</p>
<p>Long Short-Term Memory (RNN)</p>
<p>MDL:</p>
<p>Minimum Description Length</p>
<p>MDP:</p>
<p>Markov Decision Process</p>
<p>MNIST:</p>
<p>Mixed National Institute of Standards and Technology Database</p>
<p>MP:</p>
<p>Max-Pooling</p>
<p>MPCNN:</p>
<p>Max-Pooling CNN</p>
<p>NE:</p>
<p>NeuroEvolution</p>
<p>NEAT:</p>
<p>NE of Augmenting Topologies</p>
<p>NES:</p>
<p>Natural Evolution Strategies</p>
<p>NFQ:</p>
<p>Neural Fitted Q-Learning</p>
<p>NN:</p>
<p>Neural Network</p>
<p>OCR:</p>
<p>Optical Character Recognition</p>
<p>PCC:</p>
<p>Potential Causal Connection</p>
<p>PDCC:</p>
<p>Potential Direct Causal Connection</p>
<p>PM:</p>
<p>Predictability Minimization</p>
<p>POMDP:</p>
<p>Partially Observable MDP</p>
<p>RAAM:</p>
<p>Recursive Auto-Associative Memory</p>
<p>RBM:</p>
<p>Restricted Boltzmann Machine</p>
<p>ReLU:</p>
<p>Rectified Linear Unit</p>
<p>RL:</p>
<p>Reinforcement Learning</p>
<p>RNN:</p>
<p>Recurrent Neural Network</p>
<p>R-prop:</p>
<p>Resilient Backpropagation</p>
<p>SL:</p>
<p>Supervised Learning</p>
<p>SLIM NN:</p>
<p>Self-Delimiting Neural Network</p>
<p>SOTA:</p>
<p>Self-Organizing Tree Algorithm</p>
<p>SVM:</p>
<p>Support Vector Machine</p>
<p>TDNN:</p>
<p>Time-Delay Neural Network</p>
<p>TIMIT:</p>
<p>TI/SRI/MIT Acoustic-Phonetic Continuous Speech Corpus</p>
<p>UL:</p>
<p>Unsupervised Learning</p>
<p>WTA:</p>
<p>Winner-Take-All<br>[[AILanguage]] </p>
<hr>
<hr>
<h3 id="section-analyse-structur-e-en-grille-sagrid-">Section analyse structurée en grille (SAGrid)</h3>
