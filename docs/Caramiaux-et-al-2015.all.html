<hr>
<h2 id="fiche-cr-e-par-guillaume-d-isabelle-2020-">Fiche créée par Guillaume D.Isabelle, 2020 </h2>
<h3 id="hashtagged">HashTagged</h3>
<p><img src="1f5aba38-1b97-4dd0-b437-c73eeed881da" alt=""><br><img src="151a8a8f-c2dc-4c7f-a598-8dd592304f6c" alt=""><br><img src="07aa82b8-6ce7-4a7f-8e45-01174436888a" alt=""></p>
<hr>
<hr>
<h1 id="adaptive-gesture-recognition-with-variation-estimation-for-interactive-systems">Adaptive Gesture Recognition with Variation Estimation for Interactive Systems</h1>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://zotero.org/users/180474/items/XBAEC42P">ZotWeb</a></td>
<td>article-journal</td>
<td></td>
</tr>
<tr>
<td><a href="https://dl.acm.org/doi/10.1145/2643204">Src Url</a></td>
<td>[[Caramiaux]], [[Montecchio]], [[Tanaka]], [[Bevilacqua]] (2015)</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="abstract">Abstract</h2>
<p>undefined</p>
<hr>
<h2 id="annotations">Annotations</h2>
<h1 id="adaptive-gesture-recognition-with-variation-estimation-for-interactive-systems">Adaptive Gesture Recognition with Variation Estimation for Interactive Systems</h1>
<p>&lt;font size=-3&gt;Citer:(Caramiaux et al., 2015)<br><br>FTag: Caramiaux-et-al-2015<br><br>APA7: Caramiaux, B., Montecchio, N., Tanaka, A., &amp; Bevilacqua, F. (2015). Adaptive Gesture Recognition with Variation Estimation for Interactive Systems. <em>ACM Transactions on Interactive Intelligent Systems</em>, _4_(4), 1–34. <a href="https://doi.org/10.1145/2643204">https://doi.org/10.1145/2643204</a><br><br> <a href="https://app.getpolarized.io/doc/1dVJNgCTU5push7YNVgsLE43j7ZzDdBCUPjiCsTLXorLDsCNiU">Polar</a> -&lt;/font&gt;



</p>
<p>This paper presents a gesture recognition/adaptation system for Human Computer Interaction</p>
<p>These systems are fundamentally not designed to take into account variations that occur during the movement performanc</p>
<p><img src="11DhE6zmezi5NX95TuA4.png" alt=""></p>
<p>4.1. Continuous state model</p>
<p>4.2. State space model</p>
<p><img src="1wRbjQmRPCnzLAohnajS.png" alt=""></p>
<p>Fig. 3 . Gesture vocabulary from [Wobbrock et al. 2007].</p>
<p><img src="128gdzLjApxqyn6dVkUH.png" alt=""></p>
<p>Fig. 11 . Gesture variations allowed in the application: variations in size, speed and tilt. Each variation is used to control the sound feedback parameter: loudness, playback speed and filter</p>
<h1 id="conclusion">CONCLUSION</h1>
<p>r gesture recognition that can adapt and estimate in real-time variations occurring during gesture executio</p>
<p>ability of our method to track changes in phase, scaling and rotation</p>
<blockquote>
<p>[...] important feature [...] causal inference [...] represents a clear advantage for interactive applications [...] partial results are available during the gestures [...] anticipate which gesture is currently performed by early recognition.</p>
</blockquote>
<hr>
<hr>
<h3 id="section-analyse-structur-e-en-grille-sagrid-">Section analyse structurée en grille (SAGrid)</h3>
