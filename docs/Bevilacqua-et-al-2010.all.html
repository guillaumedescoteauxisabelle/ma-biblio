<hr>
<h2 id="fiche-cr-e-par-guillaume-d-isabelle-2020-">Fiche créée par Guillaume D.Isabelle, 2020 </h2>
<h3 id="hashtagged">HashTagged</h3>
<h1 id="continuous-realtime-gesture-following-and-recognition">Continuous Realtime Gesture Following and Recognition</h1>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://zotero.org/users/180474/items/PCS2SIBJ">ZotWeb</a></td>
<td>chapter</td>
<td></td>
</tr>
<tr>
<td><a href="http://link.springer.com/10.1007/978-3-642-12553-9_7">Src Url</a></td>
<td>[[Bevilacqua]], [[Zamborlin]], [[Sypniewski]], [[Schnell]], [[Guédy]], [[Rasamimanana]] (2010)</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="abstract">Abstract</h2>
<p>We present a HMM based system for real-time gesture analysis. The system outputs continuously parameters relative to the gesture time progression and its likelihood. These parameters are computed by comparing the performed gesture with stored reference gestures. The method relies on a detailed modeling of multidimensional temporal curves. Compared to standard HMM systems, the learning procedure is simpliﬁed using prior knowledge allowing the system to use a single example for each class. Several applications have been developed using this system in the context of music education, music and dance performances and interactive installation. Typically, the estimation of the time progression allows for the synchronization of physical gestures to sound ﬁles by time stretching/compressing audio buﬀers or videos.</p>
<hr>
<h2 id="annotations">Annotations</h2>
<p>Continuous Realtime Gesture Following and Recognition</p>
<p>Key words:</p>
<p>gesture recognition<br>[[GestureRecognition]] </p>
<p>gesture following<br>[[GestureFollowing]] </p>
<p>interactive systems<br>[[InteractiveSystems]] </p>
<p>&lt;font size=-3&gt;Citer: (Bevilacqua et al., 2010)<br><br>FTag: Bevilacqua-et-al-2010<br><br>APA7: Bevilacqua, F., Zamborlin, B., Sypniewski, A., Schnell, N., Guédy, F., &amp; Rasamimanana, N. (2010). Continuous Realtime Gesture Following and Recognition. In S. Kopp &amp; I. Wachsmuth (Eds.), <em>Gesture in Embodied Communication and Human-Computer Interaction</em> (Vol. 5934, pp. 73–84). Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-12553-9_7">https://doi.org/10.1007/978-3-642-12553-9_7</a><br><br> <a href="https://app.getpolarized.io/doc/12vNyoB6LznzS7PxWZqg5tdqsfgR34AVN74LudPb5N3KiUdZHqF">Polar</a>&lt;/font&gt;






</p>
<hr>
<hr>
<h3 id="section-analyse-structur-e-en-grille-sagrid-">Section analyse structurée en grille (SAGrid)</h3>
